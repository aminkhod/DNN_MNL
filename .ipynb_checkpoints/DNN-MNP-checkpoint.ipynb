{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69da6c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m F2 \u001b[38;5;241m=\u001b[39m Formula((W1, a2), (W2, b2), (W3, p2), (W4, q2))\n\u001b[0;32m     19\u001b[0m F2 \u001b[38;5;241m=\u001b[39m Formula((W1, a3), (W2, b3), (W3, p3), (W4, q3))\n\u001b[1;32m---> 21\u001b[0m \u001b[43mddd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrorDist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m history, new_model \u001b[38;5;241m=\u001b[39m ddd\u001b[38;5;241m.\u001b[39mfit_model(target)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(ddd\u001b[38;5;241m.\u001b[39mestimated_parameters())\n",
      "File \u001b[1;32mD:\\GitRep\\DNN_MNL\\RUM_DNN.py:259\u001b[0m, in \u001b[0;36mRUM_DNN.creat_model\u001b[1;34m(this, errorDist, probit)\u001b[0m\n\u001b[0;32m    257\u001b[0m rowNum, columnsNum \u001b[38;5;241m=\u001b[39m Formula\u001b[38;5;241m.\u001b[39mdataFrame\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    258\u001b[0m Utility1\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputLayer((columnsNum,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minp_1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 259\u001b[0m Utility1\u001b[38;5;241m.\u001b[39madd(\u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFormula\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformulaList\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBetaList\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBetaList\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m                         \u001b[49m\u001b[43miternum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miternum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrorDist\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    262\u001b[0m this\u001b[38;5;241m.\u001b[39mprobit \u001b[38;5;241m=\u001b[39m probit\n\u001b[0;32m    263\u001b[0m mergedOutput1 \u001b[38;5;241m=\u001b[39m Utility1\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mD:\\GitRep\\DNN_MNL\\RUM_DNN.py:76\u001b[0m, in \u001b[0;36mRUM_DNN.Dense1.__init__\u001b[1;34m(self, iternum, formula, BetaList, probit, dist, activation, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miternum \u001b[38;5;241m=\u001b[39m iternum\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m:\n\u001b[0;32m     77\u001b[0m     normal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miternum)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(dist)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miternum:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from RUM_DNN import *\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "ddd = RUM_DNN(iternum=400, epochs=200)\n",
    "Dataset = pd.read_excel('Dataset_MNP2.xlsx')\n",
    "\n",
    "Dataset.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "target = ddd.dense_to_one_hot(Dataset['choice'], 3)\n",
    "ddd.attach(Dataset)\n",
    "\n",
    "W1 = Beta('w1', 0, 0)\n",
    "W2 = Beta('w2', 0, 0)\n",
    "W3 = Beta('w3', 0, 0)\n",
    "W4 = Beta('w4', 0, 0)\n",
    "F1 = Formula((W1, a1), (W2, b1), (W3, p1), (W4, q1))\n",
    "F2 = Formula((W1, a2), (W2, b2), (W3, p2), (W4, q2))\n",
    "F2 = Formula((W1, a3), (W2, b3), (W3, p3), (W4, q3))\n",
    "\n",
    "ddd.creat_model(errorDist=normal(0, 1, 400), probit=True)\n",
    "\n",
    "history, new_model = ddd.fit_model(target)\n",
    "\n",
    "print(ddd.estimated_parameters())\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "ddd.plot_parameters_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381e0d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  \"# from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       "  \"from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       "  'globals()'],\n",
       " '_oh': {},\n",
       " '_dh': [WindowsPath('D:/GitRep/DNN_MNL')],\n",
       " 'In': ['',\n",
       "  \"# from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       "  \"from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       "  'globals()'],\n",
       " 'Out': {},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000001FD95F5D6A0>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x1fd95f3e4c0>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x1fd95f3e4c0>,\n",
       " '_': '',\n",
       " '__': '',\n",
       " '___': '',\n",
       " '_i': \"from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       " '_ii': \"# from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       " '_iii': '',\n",
       " '_i1': \"# from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       " 'timeit': <module 'timeit' from 'c:\\\\program files\\\\python38\\\\lib\\\\timeit.py'>,\n",
       " 'start': 74.4059643,\n",
       " '_i2': \"from RUM_DNN import *\\nimport timeit\\n\\nstart = timeit.default_timer()\\n\\nddd = RUM_DNN(iternum=400, epochs=200)\\nDataset = pd.read_excel('Dataset_MNP2.xlsx')\\n\\nDataset.drop('Unnamed: 0', inplace=True, axis=1)\\ntarget = ddd.dense_to_one_hot(Dataset['choice'], 3)\\nddd.attach(Dataset)\",\n",
       " 'seed': <function RandomState.seed>,\n",
       " 'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       " 'pd': <module 'pandas' from 'c:\\\\program files\\\\python38\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>,\n",
       " 'np': <module 'numpy' from 'C:\\\\Users\\\\Akhod\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\numpy\\\\__init__.py'>,\n",
       " 'plt': <module 'matplotlib.pyplot' from 'c:\\\\program files\\\\python38\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>,\n",
       " 'Beta': Beta.Beta,\n",
       " 'Formula': Formula.Formula,\n",
       " 'Constraint': keras.constraints.Constraint,\n",
       " 'activations': <module 'keras.activations' from 'c:\\\\program files\\\\python38\\\\lib\\\\site-packages\\\\keras\\\\activations.py'>,\n",
       " 'Layer': keras.engine.base_layer.Layer,\n",
       " 'Model': keras.engine.training.Model,\n",
       " 'Sequential': keras.engine.sequential.Sequential,\n",
       " 'tf': <module 'tensorflow' from 'c:\\\\program files\\\\python38\\\\lib\\\\site-packages\\\\tensorflow\\\\__init__.py'>,\n",
       " 'K': <module 'tensorflow.compat.v1.keras.backend' from 'c:\\\\program files\\\\python38\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v1\\\\keras\\\\backend\\\\__init__.py'>,\n",
       " 'beta': <function RandomState.beta>,\n",
       " 'binomial': <function RandomState.binomial>,\n",
       " 'bytes': <function RandomState.bytes>,\n",
       " 'chisquare': <function RandomState.chisquare>,\n",
       " 'choice': <function RandomState.choice>,\n",
       " 'dirichlet': <function RandomState.dirichlet>,\n",
       " 'exponential': <function RandomState.exponential>,\n",
       " 'f': <function RandomState.f>,\n",
       " 'gamma': <function RandomState.gamma>,\n",
       " 'geometric': <function RandomState.geometric>,\n",
       " 'get_state': <function RandomState.get_state>,\n",
       " 'gumbel': <function RandomState.gumbel>,\n",
       " 'hypergeometric': <function RandomState.hypergeometric>,\n",
       " 'laplace': <function RandomState.laplace>,\n",
       " 'logistic': <function RandomState.logistic>,\n",
       " 'lognormal': <function RandomState.lognormal>,\n",
       " 'logseries': <function RandomState.logseries>,\n",
       " 'multinomial': <function RandomState.multinomial>,\n",
       " 'multivariate_normal': <function RandomState.multivariate_normal>,\n",
       " 'negative_binomial': <function RandomState.negative_binomial>,\n",
       " 'noncentral_chisquare': <function RandomState.noncentral_chisquare>,\n",
       " 'noncentral_f': <function RandomState.noncentral_f>,\n",
       " 'normal': <function RandomState.normal>,\n",
       " 'pareto': <function RandomState.pareto>,\n",
       " 'permutation': <function RandomState.permutation>,\n",
       " 'poisson': <function RandomState.poisson>,\n",
       " 'power': <function RandomState.power>,\n",
       " 'rand': <function RandomState.rand>,\n",
       " 'randint': <function RandomState.randint>,\n",
       " 'randn': <function RandomState.randn>,\n",
       " 'random': <function RandomState.random>,\n",
       " 'random_integers': <function RandomState.random_integers>,\n",
       " 'random_sample': <function RandomState.random_sample>,\n",
       " 'ranf': <function numpy.random.mtrand.ranf>,\n",
       " 'rayleigh': <function RandomState.rayleigh>,\n",
       " 'sample': <function numpy.random.mtrand.sample>,\n",
       " 'set_state': <function RandomState.set_state>,\n",
       " 'shuffle': <function RandomState.shuffle>,\n",
       " 'standard_cauchy': <function RandomState.standard_cauchy>,\n",
       " 'standard_exponential': <function RandomState.standard_exponential>,\n",
       " 'standard_gamma': <function RandomState.standard_gamma>,\n",
       " 'standard_normal': <function RandomState.standard_normal>,\n",
       " 'standard_t': <function RandomState.standard_t>,\n",
       " 'triangular': <function RandomState.triangular>,\n",
       " 'uniform': <function RandomState.uniform>,\n",
       " 'vonmises': <function RandomState.vonmises>,\n",
       " 'wald': <function RandomState.wald>,\n",
       " 'weibull': <function RandomState.weibull>,\n",
       " 'zipf': <function RandomState.zipf>,\n",
       " 'Generator': numpy.random._generator.Generator,\n",
       " 'RandomState': numpy.random.mtrand.RandomState,\n",
       " 'SeedSequence': numpy.random.bit_generator.SeedSequence,\n",
       " 'MT19937': numpy.random._mt19937.MT19937,\n",
       " 'Philox': numpy.random._philox.Philox,\n",
       " 'PCG64': numpy.random._pcg64.PCG64,\n",
       " 'PCG64DXSM': numpy.random._pcg64.PCG64DXSM,\n",
       " 'SFC64': numpy.random._sfc64.SFC64,\n",
       " 'default_rng': <function numpy.random._generator.default_rng>,\n",
       " 'BitGenerator': numpy.random.bit_generator.BitGenerator,\n",
       " 'RUM_DNN': RUM_DNN.RUM_DNN,\n",
       " 'ddd': <RUM_DNN.RUM_DNN at 0x1fd96194ee0>,\n",
       " 'Dataset':             a1        b1        p1        q1        a2        b2        p2  \\\n",
       " 0     0.199542 -0.495365  5.399283  3.717275  0.612988  0.265638  5.304003   \n",
       " 1    -0.060040  0.224597  3.714681  0.599263 -0.563582  0.587916  6.132863   \n",
       " 2     0.603076  0.771170  6.162910 -0.776224  0.258495 -0.611385  4.949414   \n",
       " 3     0.817504  0.128046  5.992486 -1.196539 -0.123020 -0.135230  5.859212   \n",
       " 4    -0.244206 -0.901741  5.138929  2.104317  0.669712  0.313280  5.348626   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 9995  0.015817 -0.182655  4.943019  0.787172  0.552700  0.212979  5.530609   \n",
       " 9996  0.896134  0.163276  3.398767 -1.267212 -0.119713  0.786717  6.379346   \n",
       " 9997 -0.248120 -0.136959  4.695284  0.393614  0.538099 -0.032047  4.168586   \n",
       " 9998  0.872425  0.120991  4.645536 -0.568759  0.098492  0.311065  5.449579   \n",
       " 9999  0.286201 -0.516254  5.452570 -1.749068  0.876001  0.436147  5.492600   \n",
       " \n",
       "             q2        a3        b3        p3        q3  choice  \n",
       " 0     0.831130 -0.511259 -0.004354  4.058667  1.433343       0  \n",
       " 1    -0.597496  0.698413  0.934300  4.905764  2.219185       0  \n",
       " 2    -1.398444  0.254990 -0.505089  6.257880 -0.744235       1  \n",
       " 3     2.432418 -0.075670 -0.318204  4.380850  2.386472       1  \n",
       " 4    -1.400971  0.292705 -0.398365  5.596103 -1.038300       0  \n",
       " ...        ...       ...       ...       ...       ...     ...  \n",
       " 9995  1.271806  0.279871 -0.573416  4.571094 -1.154275       1  \n",
       " 9996 -0.681801 -0.242577 -0.567547  6.048504  1.523501       0  \n",
       " 9997  1.955167  0.214848 -0.083291  4.697117  2.495158       1  \n",
       " 9998  0.647607  0.786180  0.425225  5.616254 -0.824248       1  \n",
       " 9999 -0.317213  0.506802  0.243971  4.626493  0.351203       2  \n",
       " \n",
       " [10000 rows x 13 columns],\n",
       " 'target': array([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]]),\n",
       " '_i3': 'globals()'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e979414",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma1\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a1' is not defined"
     ]
    }
   ],
   "source": [
    "a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38700d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W1 = Beta('w1', 0, 0)\n",
    "W2 = Beta('w2', 0, 0)\n",
    "W3 = Beta('w3', 0, 0)\n",
    "W4 = Beta('w4', 0, 0)\n",
    "F1 = Formula((W1, a1), (W2, b1), (W3, p1), (W4, q1))\n",
    "F2 = Formula((W1, a2), (W2, b2), (W3, p2), (W4, q2))\n",
    "F2 = Formula((W1, a3), (W2, b3), (W3, p3), (W4, q3))\n",
    "\n",
    "ddd.creat_model(errorDist=normal(0, 1, 45), probit=True)\n",
    "\n",
    "history, new_model = ddd.fit_model(target)\n",
    "\n",
    "print(ddd.estimated_parameters())\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "ddd.plot_parameters_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288fab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0', 'a1', 'b1', 'p1', 'q1', 'a2', 'b2', 'p2', 'q2', 'choice', 'de']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(df.columns)\n",
    "z.append('de')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "322147e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>b1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.368596</td>\n",
       "      <td>-0.803612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944801</td>\n",
       "      <td>-0.474129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303643</td>\n",
       "      <td>0.565079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457567</td>\n",
       "      <td>0.255848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.094776</td>\n",
       "      <td>-0.057214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.369153</td>\n",
       "      <td>-0.204580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.869922</td>\n",
       "      <td>0.375685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.340055</td>\n",
       "      <td>0.020620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.604374</td>\n",
       "      <td>-0.446506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.911111</td>\n",
       "      <td>-0.768189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            a1        b1\n",
       "0    -0.368596 -0.803612\n",
       "1     0.944801 -0.474129\n",
       "2     0.303643  0.565079\n",
       "3     0.457567  0.255848\n",
       "4    -0.094776 -0.057214\n",
       "...        ...       ...\n",
       "9995  0.369153 -0.204580\n",
       "9996  0.869922  0.375685\n",
       "9997  0.340055  0.020620\n",
       "9998 -0.604374 -0.446506\n",
       "9999 -0.911111 -0.768189\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset_MNL.csv', sep=' ')\n",
    "# global().update(df.columns)\n",
    "df1 = pd.DataFrame()\n",
    "z = list(df1.columns)\n",
    "z.append('a1')\n",
    "df1 = pd.concat([df1, df['a1']],axis=1)\n",
    "z.append('b1')\n",
    "df1 = pd.concat([df1, df['b1']],axis=1)\n",
    "df1.columns = z\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b316cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Created on Wed Jun 22 10:46:24 2022\n",
    "\n",
    "@author: Niousha\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"library_____________________________________________________________________\"\"\"\n",
    "import timeit\n",
    "from random import seed\n",
    "seed(1)\n",
    "start = timeit.default_timer()\n",
    "\n",
    "import timeit\n",
    "from random import seed\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.constraints import Constraint\n",
    "\n",
    "import math\n",
    "\"\"\"Dataset_____________________________________________________________________\"\"\"\n",
    "\n",
    "# Bp = -1\n",
    "# Ba = 0.5\n",
    "# Bb = 0.5\n",
    "# Bq = 1\n",
    "\n",
    "# Dataset = pd.read_excel('Dataset_MNP.xlsx')\n",
    "\n",
    "# cor = pd.read_excel('Cor_MNP.xlsx')\n",
    "\n",
    "# cor.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "\n",
    "# True_val= [Bp,Ba,Bb,Bq,cor.iloc[1,0]]\n",
    "\n",
    "# Dataset.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "# def dense_to_one_hot(labels_dense, num_classes):\n",
    "#     labels_dense = labels_dense.astype(np.int64)\n",
    "#     num_labels = labels_dense.shape[0]\n",
    "#     index_offset = np.arange(num_labels) * num_classes\n",
    "#     labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "#     labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "\n",
    "#     return labels_one_hot\n",
    "\n",
    "# classes = dense_to_one_hot(labels_dense=Dataset['choice'], num_classes=2)\n",
    "\"\"\"DNN Model___________________________________________________________________\"\"\"\n",
    "\n",
    "from keras import activations\n",
    "from keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "                                   \n",
    "\n",
    "class DNN_MNP():\n",
    "    def __init__(this, formula = 'y ~ .', batch = 100\n",
    "        iternum=200):\n",
    "        this.formula = formoula\n",
    "        this.batch = batch\n",
    "        this.iternum = iternum\n",
    "        \n",
    "    \n",
    "    class Dense1(Layer):\n",
    "        def __init__(self,\n",
    "                     units,batch,iternum,\n",
    "                     activation=None, **kwargs):\n",
    "            self.units = units\n",
    "            self.activation = activations.get(activation)\n",
    "            self.batch = batch\n",
    "            self.iternum = iternum\n",
    "\n",
    "\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "        def build(self, input_shape):\n",
    "\n",
    "\n",
    "            self.W1 = self.add_weight(name='Ba',shape=(1,))\n",
    "            self.W2 = self.add_weight(name='Bb',shape=(1,))\n",
    "            self.W3 = self.add_weight(name='Bp',shape=(1,))\n",
    "            self.W4 = self.add_weight(name='Bq',shape=(1,))\n",
    "            self.W5 = self.add_weight(name='cor',shape=(1,),initializer = tf.keras.initializers.Constant(0.5),\n",
    "                                          trainable=True,constraint=tf.keras.constraints.MinMaxNorm(max_value=0.98))\n",
    "\n",
    "            super().build(input_shape)\n",
    "\n",
    "        def call(self, inputs, **kwargs):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Error1= np.random.normal(loc = 0, scale = 1 , size = (self.iternum,))\n",
    "            Error2= np.random.normal(loc = 0, scale = 1 , size = (self.iternum,))\n",
    "\n",
    "\n",
    "\n",
    "            inp=tf.cast(tf.transpose(tf.stack((Error1,Error2))), tf.float32)\n",
    "            o=tf.constant([0.0])\n",
    "            p=tf.constant([1.0])\n",
    "\n",
    "\n",
    "\n",
    "            row1=tf.reshape(tf.stack([p,o]),(2,))\n",
    "\n",
    "            row2=tf.reshape(tf.stack([self.W5,tf.sqrt(p-tf.square(self.W5))]),(2,))\n",
    "\n",
    "            L = tf.stack([row1,row2])\n",
    "\n",
    "            error=self.activation(tf.matmul(inp,L))\n",
    "\n",
    "            v1 = tf.expand_dims((self.W1 * inputs[:,0]) + (self.W2 * inputs[:,1]) + (self.W3 * inputs[:,2]) + (self.W4 * inputs[:,3]),axis = 1)\n",
    "\n",
    "\n",
    "            out1=tf.expand_dims(tf.matmul(v1,tf.ones((1, self.iternum), tf.float32))+ error[:,0],axis = 1)\n",
    "        \n",
    "\n",
    "\n",
    "            v2 =tf.expand_dims((self.W1 * inputs[:,4]) + (self.W2 * inputs[:,5]) + (self.W3 * inputs[:,6])+ (self.W4 * inputs[:,7]),axis = 1)\n",
    "\n",
    "            out2=tf.expand_dims(tf.matmul(v2,tf.ones((1, self.iternum), tf.float32))+ error[:,1],axis = 1)\n",
    "            out1 = out1 - out2\n",
    "\n",
    "            out2 = out2 - out2\n",
    "\n",
    "            Scores = tf.experimental.numpy.hstack((out1, out2))\n",
    "\n",
    "\n",
    "            return Scores\n",
    "\n",
    "\n",
    "        def F(x):  \n",
    "            return x\n",
    "\n",
    "\n",
    "    def creat_model(this)\n",
    "        Utility1 = Sequential()\n",
    "\n",
    "        batch = 100\n",
    "        iternum=200\n",
    "\n",
    "        Utility1.add(tf.keras.layers.InputLayer((8,), batch_size=batch,name='inp_1'))\n",
    "        Utility1.add(Dense1(1,batch,iternum=iternum,activation=F))\n",
    "\n",
    "\n",
    "\n",
    "        mergedOutput1=Utility1.output\n",
    "\n",
    "\n",
    "\n",
    "        mergedOutput=tf.transpose(mergedOutput1, perm=[0,2,1])\n",
    "\n",
    "\n",
    "        beta=1e4\n",
    "        mergedOutput = tf.nn.softmax(mergedOutput*beta)\n",
    "\n",
    "\n",
    "        mergedOutput=tf.reduce_sum(mergedOutput, 1)\n",
    "\n",
    "\n",
    "\n",
    "        Sum=tf.reduce_sum(mergedOutput, 1)\n",
    "\n",
    "        main_network= tf.transpose(tf.divide(tf.transpose(mergedOutput),Sum))\n",
    "\n",
    "\n",
    "\n",
    "        new_model = Model(\n",
    "        inputs=[Utility1.input], outputs=[main_network])\n",
    "\n",
    "\n",
    "        print(new_model.summary())\n",
    "\n",
    "\n",
    "        def compile_model(this, new_model):\n",
    "            new_model.compile(optimizer= 'adam', loss='categorical_crossentropy'  ,metrics=['categorical_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "cbk = tf.keras.callbacks.LambdaCallback( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:new_model.get_weights()}))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping( monitor='loss',patience=20,mode='min')\n",
    "\n",
    "\n",
    "epochs=500\n",
    "\n",
    "history=new_model.fit( Dataset.iloc[:, 0:8 ],classes, epochs=epochs ,batch_size=batch,shuffle=True,callbacks=[cbk])\n",
    "\n",
    "\"\"\"Extracting Weights__________________________________________________________\"\"\"\n",
    "\n",
    "weight = [layer.get_weights() for layer in new_model.layers]\n",
    "\n",
    "a = [weight[1][0],weight[1][1],weight[1][2],weight[1][3],weight[1][4]]\n",
    "\n",
    "\n",
    "\n",
    "parameters= np.array(a)\n",
    "\n",
    "\"\"\"Extracting Weights__________________________________________________________\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_epochs = np.zeros((5,epochs))\n",
    "\n",
    "for i in range(epochs):\n",
    "    weights_epochs[0,i]=weights_dict[i][0]\n",
    "    weights_epochs[1,i]=weights_dict[i][1]\n",
    "    weights_epochs[2,i]=weights_dict[i][2]\n",
    "    weights_epochs[3,i]=weights_dict[i][3]\n",
    "    weights_epochs[4,i]=weights_dict[i][4]\n",
    "\n",
    "\n",
    "    \n",
    "epoch = np.arange(1, epochs+1, 1)  \n",
    "plt.plot(epoch, weights_epochs[0, :], label = \"Ba\")\n",
    "plt.plot(epoch, weights_epochs[1, :],label = \"Bb\")\n",
    "plt.plot(epoch, weights_epochs[2, :],label = \"Bp\")\n",
    "plt.plot(epoch, weights_epochs[3, :],label = \"Bq\")\n",
    "plt.plot(epoch, weights_epochs[4, :],label = \"correlation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('weights')\n",
    "plt.ylabel('weights')\n",
    "#plt.ylim(-13,+13)\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"weights_____________________________________________________________________\"\"\"\n",
    "\n",
    "weights=[Ba,Bb,Bp,Bq,cor.iloc[1,0]]\n",
    "\n",
    "\n",
    "k=[-1.5,0.0,0.1,0.2,0.3,0.4,0.5,1.5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(weights, parameters,marker='o', color='blue')\n",
    "ax.plot(k,k,color='green', linestyle='dashed',label=\"f(x)=x\")\n",
    "ax.set_title( 'Deep neural network')\n",
    "ax.set_ylabel('Estimated values')\n",
    "ax.set_xlabel('True values')\n",
    "ax.grid(True)\n",
    "plt.ylim(-1.5, +1.5) \n",
    "plt.xlim(-1.5, +1.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\" Time \"\"\"\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" list all data in history___________________________________________________\"\"\"\n",
    "\n",
    "# print(history.history.keys())\n",
    "\n",
    "\"\"\" summarise history for accuracy_____________________________________________\"\"\"\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim(0.0, +1.0)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" summarise history for loss_________________________________________________\"\"\"\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"STANDARD ERROR______________________________________________________________\"\"\"\n",
    "\n",
    "matrix1 = np.zeros((4,4))\n",
    "\n",
    "Data = Dataset.iloc[:,0:8]\n",
    "\n",
    "y_pred = new_model.predict(Dataset.iloc[:, 1:11 ])\n",
    "\n",
    "\n",
    "pred = pd.DataFrame(np.concatenate((y_pred[:,0:1],y_pred[:,0:1],\n",
    "                                    y_pred[:,1:2],y_pred[:,1:2]), axis= 1))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        matrix1[i,j]= np.sum((Data.iloc[:,i] * Data.iloc[:,j]) * (pred.iloc[:,i]*pred.iloc[:,j]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "invHess1 = np.linalg.inv(matrix1)\n",
    "\n",
    "stds1 = [invHess1[i][i]**0.5 for i in range(invHess1.shape[0])]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"End_________________________________________________________________________\"\"\"\n",
    "\n",
    "\n",
    "# stop = timeit.default_timer()\n",
    "\n",
    "# print('Time: ', stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
