{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69da6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68125cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0', 'a1', 'b1', 'p1', 'q1', 'a2', 'b2', 'p2', 'q2', 'choice', 'de']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = list(df.columns)\n",
    "z.append('de')\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "322147e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.803612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.474129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.565079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.057214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.204580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.375685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.020620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.446506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.768189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            b1\n",
       "0    -0.803612\n",
       "1    -0.474129\n",
       "2     0.565079\n",
       "3     0.255848\n",
       "4    -0.057214\n",
       "...        ...\n",
       "9995 -0.204580\n",
       "9996  0.375685\n",
       "9997  0.020620\n",
       "9998 -0.446506\n",
       "9999 -0.768189\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset_MNL.csv', sep=' ')\n",
    "# global().update(df.columns)\n",
    "df1 = pd.DataFrame()\n",
    "z = list(df1.columns)\n",
    "z.append('a1')\n",
    "df1 = pd.concat([df1, df['a1']])\n",
    "z.append('b1')\n",
    "df1 = pd.concat([df1, df['b1']])\n",
    "df1.columns = z\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b316cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Created on Wed Jun 22 10:46:24 2022\n",
    "\n",
    "@author: Niousha\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"library_____________________________________________________________________\"\"\"\n",
    "import timeit\n",
    "from random import seed\n",
    "seed(1)\n",
    "start = timeit.default_timer()\n",
    "\n",
    "import timeit\n",
    "from random import seed\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.constraints import Constraint\n",
    "\n",
    "import math\n",
    "\"\"\"Dataset_____________________________________________________________________\"\"\"\n",
    "\n",
    "# Bp = -1\n",
    "# Ba = 0.5\n",
    "# Bb = 0.5\n",
    "# Bq = 1\n",
    "\n",
    "# Dataset = pd.read_excel('Dataset_MNP.xlsx')\n",
    "\n",
    "# cor = pd.read_excel('Cor_MNP.xlsx')\n",
    "\n",
    "# cor.drop('Unnamed: 0', inplace=True, axis=1) \n",
    "\n",
    "# True_val= [Bp,Ba,Bb,Bq,cor.iloc[1,0]]\n",
    "\n",
    "# Dataset.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "# def dense_to_one_hot(labels_dense, num_classes):\n",
    "#     labels_dense = labels_dense.astype(np.int64)\n",
    "#     num_labels = labels_dense.shape[0]\n",
    "#     index_offset = np.arange(num_labels) * num_classes\n",
    "#     labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "#     labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "\n",
    "#     return labels_one_hot\n",
    "\n",
    "# classes = dense_to_one_hot(labels_dense=Dataset['choice'], num_classes=2)\n",
    "\"\"\"DNN Model___________________________________________________________________\"\"\"\n",
    "\n",
    "from keras import activations\n",
    "from keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "                                   \n",
    "\n",
    "class DNN_MNP():\n",
    "    def __init__(this, formula = 'y ~ .', batch = 100\n",
    "        iternum=200):\n",
    "        this.formula = formoula\n",
    "        this.batch = batch\n",
    "        this.iternum = iternum\n",
    "        \n",
    "    \n",
    "    class Dense1(Layer):\n",
    "        def __init__(self,\n",
    "                     units,batch,iternum,\n",
    "                     activation=None, **kwargs):\n",
    "            self.units = units\n",
    "            self.activation = activations.get(activation)\n",
    "            self.batch = batch\n",
    "            self.iternum = iternum\n",
    "\n",
    "\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "        def build(self, input_shape):\n",
    "\n",
    "\n",
    "            self.W1 = self.add_weight(name='Ba',shape=(1,))\n",
    "            self.W2 = self.add_weight(name='Bb',shape=(1,))\n",
    "            self.W3 = self.add_weight(name='Bp',shape=(1,))\n",
    "            self.W4 = self.add_weight(name='Bq',shape=(1,))\n",
    "            self.W5 = self.add_weight(name='cor',shape=(1,),initializer = tf.keras.initializers.Constant(0.5),\n",
    "                                          trainable=True,constraint=tf.keras.constraints.MinMaxNorm(max_value=0.98))\n",
    "\n",
    "            super().build(input_shape)\n",
    "\n",
    "        def call(self, inputs, **kwargs):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Error1= np.random.normal(loc = 0, scale = 1 , size = (self.iternum,))\n",
    "            Error2= np.random.normal(loc = 0, scale = 1 , size = (self.iternum,))\n",
    "\n",
    "\n",
    "\n",
    "            inp=tf.cast(tf.transpose(tf.stack((Error1,Error2))), tf.float32)\n",
    "            o=tf.constant([0.0])\n",
    "            p=tf.constant([1.0])\n",
    "\n",
    "\n",
    "\n",
    "            row1=tf.reshape(tf.stack([p,o]),(2,))\n",
    "\n",
    "            row2=tf.reshape(tf.stack([self.W5,tf.sqrt(p-tf.square(self.W5))]),(2,))\n",
    "\n",
    "            L = tf.stack([row1,row2])\n",
    "\n",
    "            error=self.activation(tf.matmul(inp,L))\n",
    "\n",
    "            v1 = tf.expand_dims((self.W1 * inputs[:,0]) + (self.W2 * inputs[:,1]) + (self.W3 * inputs[:,2]) + (self.W4 * inputs[:,3]),axis = 1)\n",
    "\n",
    "\n",
    "            out1=tf.expand_dims(tf.matmul(v1,tf.ones((1, self.iternum), tf.float32))+ error[:,0],axis = 1)\n",
    "        \n",
    "\n",
    "\n",
    "            v2 =tf.expand_dims((self.W1 * inputs[:,4]) + (self.W2 * inputs[:,5]) + (self.W3 * inputs[:,6])+ (self.W4 * inputs[:,7]),axis = 1)\n",
    "\n",
    "            out2=tf.expand_dims(tf.matmul(v2,tf.ones((1, self.iternum), tf.float32))+ error[:,1],axis = 1)\n",
    "            out1 = out1 - out2\n",
    "\n",
    "            out2 = out2 - out2\n",
    "\n",
    "            Scores = tf.experimental.numpy.hstack((out1, out2))\n",
    "\n",
    "\n",
    "            return Scores\n",
    "\n",
    "\n",
    "        def F(x):  \n",
    "            return x\n",
    "\n",
    "\n",
    "    def creat_model(this)\n",
    "        Utility1 = Sequential()\n",
    "\n",
    "        batch = 100\n",
    "        iternum=200\n",
    "\n",
    "        Utility1.add(tf.keras.layers.InputLayer((8,), batch_size=batch,name='inp_1'))\n",
    "        Utility1.add(Dense1(1,batch,iternum=iternum,activation=F))\n",
    "\n",
    "\n",
    "\n",
    "        mergedOutput1=Utility1.output\n",
    "\n",
    "\n",
    "\n",
    "        mergedOutput=tf.transpose(mergedOutput1, perm=[0,2,1])\n",
    "\n",
    "\n",
    "        beta=1e4\n",
    "        mergedOutput = tf.nn.softmax(mergedOutput*beta)\n",
    "\n",
    "\n",
    "        mergedOutput=tf.reduce_sum(mergedOutput, 1)\n",
    "\n",
    "\n",
    "\n",
    "        Sum=tf.reduce_sum(mergedOutput, 1)\n",
    "\n",
    "        main_network= tf.transpose(tf.divide(tf.transpose(mergedOutput),Sum))\n",
    "\n",
    "\n",
    "\n",
    "        new_model = Model(\n",
    "        inputs=[Utility1.input], outputs=[main_network])\n",
    "\n",
    "\n",
    "        print(new_model.summary())\n",
    "\n",
    "\n",
    "        def compile_model(this, new_model):\n",
    "            new_model.compile(optimizer= 'adam', loss='categorical_crossentropy'  ,metrics=['categorical_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_dict = {}\n",
    "\n",
    "cbk = tf.keras.callbacks.LambdaCallback( on_epoch_end=lambda epoch, logs: weights_dict.update({epoch:new_model.get_weights()}))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping( monitor='loss',patience=20,mode='min')\n",
    "\n",
    "\n",
    "epochs=500\n",
    "\n",
    "history=new_model.fit( Dataset.iloc[:, 0:8 ],classes, epochs=epochs ,batch_size=batch,shuffle=True,callbacks=[cbk])\n",
    "\n",
    "\"\"\"Extracting Weights__________________________________________________________\"\"\"\n",
    "\n",
    "weight = [layer.get_weights() for layer in new_model.layers]\n",
    "\n",
    "a = [weight[1][0],weight[1][1],weight[1][2],weight[1][3],weight[1][4]]\n",
    "\n",
    "\n",
    "\n",
    "parameters= np.array(a)\n",
    "\n",
    "\"\"\"Extracting Weights__________________________________________________________\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights_epochs = np.zeros((5,epochs))\n",
    "\n",
    "for i in range(epochs):\n",
    "    weights_epochs[0,i]=weights_dict[i][0]\n",
    "    weights_epochs[1,i]=weights_dict[i][1]\n",
    "    weights_epochs[2,i]=weights_dict[i][2]\n",
    "    weights_epochs[3,i]=weights_dict[i][3]\n",
    "    weights_epochs[4,i]=weights_dict[i][4]\n",
    "\n",
    "\n",
    "    \n",
    "epoch = np.arange(1, epochs+1, 1)  \n",
    "plt.plot(epoch, weights_epochs[0, :], label = \"Ba\")\n",
    "plt.plot(epoch, weights_epochs[1, :],label = \"Bb\")\n",
    "plt.plot(epoch, weights_epochs[2, :],label = \"Bp\")\n",
    "plt.plot(epoch, weights_epochs[3, :],label = \"Bq\")\n",
    "plt.plot(epoch, weights_epochs[4, :],label = \"correlation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('weights')\n",
    "plt.ylabel('weights')\n",
    "#plt.ylim(-13,+13)\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"weights_____________________________________________________________________\"\"\"\n",
    "\n",
    "weights=[Ba,Bb,Bp,Bq,cor.iloc[1,0]]\n",
    "\n",
    "\n",
    "k=[-1.5,0.0,0.1,0.2,0.3,0.4,0.5,1.5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(weights, parameters,marker='o', color='blue')\n",
    "ax.plot(k,k,color='green', linestyle='dashed',label=\"f(x)=x\")\n",
    "ax.set_title( 'Deep neural network')\n",
    "ax.set_ylabel('Estimated values')\n",
    "ax.set_xlabel('True values')\n",
    "ax.grid(True)\n",
    "plt.ylim(-1.5, +1.5) \n",
    "plt.xlim(-1.5, +1.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\" Time \"\"\"\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" list all data in history___________________________________________________\"\"\"\n",
    "\n",
    "# print(history.history.keys())\n",
    "\n",
    "\"\"\" summarise history for accuracy_____________________________________________\"\"\"\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim(0.0, +1.0)\n",
    "plt.show()\n",
    "\n",
    "\"\"\" summarise history for loss_________________________________________________\"\"\"\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"STANDARD ERROR______________________________________________________________\"\"\"\n",
    "\n",
    "matrix1 = np.zeros((4,4))\n",
    "\n",
    "Data = Dataset.iloc[:,0:8]\n",
    "\n",
    "y_pred = new_model.predict(Dataset.iloc[:, 1:11 ])\n",
    "\n",
    "\n",
    "pred = pd.DataFrame(np.concatenate((y_pred[:,0:1],y_pred[:,0:1],\n",
    "                                    y_pred[:,1:2],y_pred[:,1:2]), axis= 1))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        matrix1[i,j]= np.sum((Data.iloc[:,i] * Data.iloc[:,j]) * (pred.iloc[:,i]*pred.iloc[:,j]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "invHess1 = np.linalg.inv(matrix1)\n",
    "\n",
    "stds1 = [invHess1[i][i]**0.5 for i in range(invHess1.shape[0])]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"End_________________________________________________________________________\"\"\"\n",
    "\n",
    "\n",
    "# stop = timeit.default_timer()\n",
    "\n",
    "# print('Time: ', stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
